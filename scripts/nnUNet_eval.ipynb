{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kseg nnUNet Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Quantitative Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from torchmetrics import Specificity, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_recall_specificity(pred, gt, num_classes):\n",
    "    # Flatten tensor\n",
    "    pred = torch.flatten(pred.int())\n",
    "    gt = torch.flatten(gt.int())\n",
    "\n",
    "    if num_classes == 2:\n",
    "        num_classes -= 1\n",
    "\n",
    "    # Calculate recall and specificity\n",
    "    recall_metric = Recall(\n",
    "        num_classes=num_classes, average='none', multiclass=(num_classes > 1)\n",
    "    )\n",
    "    specificity_metric = Specificity(\n",
    "        num_classes=num_classes, average='none', multiclass=(num_classes > 1)\n",
    "    )\n",
    "    per_class_recall = recall_metric(pred, gt)\n",
    "    avg_recall = per_class_recall.mean()\n",
    "    per_class_specificity = specificity_metric(pred, gt)\n",
    "    avg_specificity = per_class_specificity.mean()\n",
    "    return (\n",
    "        avg_recall,\n",
    "        per_class_recall,\n",
    "        avg_specificity,\n",
    "        per_class_specificity,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_dice(y_pred, y_true, num_classes, smooth=1):\n",
    "    # Convert ordinal encoded tensors to one-hot encoded tensors\n",
    "    y_pred = torch.nn.functional.one_hot(y_pred.long(), num_classes=num_classes)\n",
    "    y_true = torch.nn.functional.one_hot(y_true.long(), num_classes=num_classes)\n",
    "\n",
    "    # Calculate intersection and union\n",
    "    intersection = torch.sum(y_pred * y_true, dim=(0, 1, 2))\n",
    "    union = torch.sum(y_pred + y_true, dim=(0, 1, 2))\n",
    "\n",
    "    # Calculate Dice score for each class\n",
    "    dice_scores = (2.0 * intersection + smooth) / (union + smooth)\n",
    "\n",
    "    # Return average Dice score and per class Dice score\n",
    "    return dice_scores.mean(), dice_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gt_dir = \"/Users/me/upenn/preprocessed/test/\"\n",
    "# pred_dir = \"/Users/me/nnUNet/nnUNet_Prediction_Results/Task508_UPenn_GBM_SS/\"\n",
    "gt_dir = \"/Users/me/oasis/preprocessed/test/\"\n",
    "pred_dir = \"/Users/me/nnUNet/nnUNet_Prediction_Results/Task509_Oasis_Tissue/\"\n",
    "\n",
    "# Assuming both directories have the same number of files and ordering\n",
    "gt_files = sorted(os.listdir(gt_dir))\n",
    "pred_files = sorted(os.listdir(pred_dir))\n",
    "\n",
    "avg_dice_scores = []\n",
    "avg_per_class_dice_scores = []\n",
    "avg_spec_scores = []\n",
    "avg_per_class_spec_scores = []\n",
    "avg_rec_scores = []\n",
    "avg_per_class_rec_scores = []\n",
    "\n",
    "for gt_file, pred_file in zip(gt_files, pred_files):\n",
    "    if not gt_file.endswith(\".nii.gz\") or not pred_file.endswith(\".nii.gz\"):\n",
    "        continue\n",
    "\n",
    "    gt_path = os.path.join(gt_dir, gt_file)\n",
    "    pred_path = os.path.join(pred_dir, pred_file)\n",
    "\n",
    "    input_image = nib.load(gt_path)\n",
    "    pred_image = nib.load(pred_path)\n",
    "\n",
    "    y_true = torch.Tensor(input_image.get_fdata())\n",
    "    y_pred = torch.Tensor(pred_image.get_fdata())\n",
    "\n",
    "    num_classes = int(torch.max(y_true) + 1)\n",
    "\n",
    "    # Calculate Dice\n",
    "    avg_dice, dice = calculate_dice(y_pred, y_true, num_classes)\n",
    "\n",
    "    # Calculate Recall and Specificity\n",
    "    avg_rec, rec, avg_spec, spec = calculate_recall_specificity(y_pred, y_true, \n",
    "                                                                num_classes)\n",
    "    # Log intermediate scores\n",
    "    avg_dice_scores.append(avg_dice)\n",
    "    avg_per_class_dice_scores.append(dice)\n",
    "    avg_rec_scores.append(avg_rec)\n",
    "    avg_per_class_rec_scores.append(rec)\n",
    "    avg_spec_scores.append(avg_spec)\n",
    "    avg_per_class_spec_scores.append(spec)\n",
    "\n",
    "overall_avg_dice = np.mean(avg_dice_scores)\n",
    "overall_per_class_dice = np.mean(avg_per_class_dice_scores, axis=0)\n",
    "overall_avg_rec = np.mean(avg_rec_scores)\n",
    "overall_per_class_rec = np.mean(avg_per_class_rec_scores, axis=0)\n",
    "overall_avg_spec = np.mean(avg_spec_scores)\n",
    "overall_per_class_spec = np.mean(avg_per_class_spec_scores, axis=0)\n",
    "\n",
    "print(\"\\nOverall Average Dice Score:\", overall_avg_dice)\n",
    "print(\"Overall Average Per Class Dice:\", overall_per_class_dice)\n",
    "print(\"Overall Average Specificity:\", overall_avg_spec)\n",
    "print(\"Overall Average Per Class Specificity:\", overall_per_class_spec)\n",
    "print(\"Overall Average Recall:\", overall_avg_rec)\n",
    "print(\"Overall Average Per Class Recall:\", overall_per_class_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Qualitative Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identifier = '0'\n",
    "# input_file = f'/Users/me/nnUNet/nnUNet_raw_data_base/nnUNet_raw_data/Task509_Oasis_Tissue/imagesTs/{identifier}_0000.nii.gz'\n",
    "# gt_file = f'/Users/me/oasis/preprocessed/test/label_{identifier}.nii.gz'\n",
    "# pred_file = f'/Users/me/nnUNet/nnUNet_Prediction_Results/Task509_Oasis_Tissue/{identifier}.nii.gz'\n",
    "input_file = f'/Users/me/nnUNet/nnUNet_raw_data_base/nnUNet_raw_data/Task508_UPenn_GBM_SS/imagesTs/{identifier}_0000.nii.gz'\n",
    "gt_file = f'/Users/me/upenn/preprocessed/test/label_{identifier}.nii.gz'\n",
    "pred_file = f'/Users/me/nnUNet/nnUNet_Prediction_Results/Task508_UPenn_GBM_SS/{identifier}.nii.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = nib.load(input_file)\n",
    "gt_image = nib.load(gt_file)\n",
    "pred_image = nib.load(pred_file)\n",
    "\n",
    "x = input_image.get_fdata()\n",
    "y = gt_image.get_fdata()\n",
    "y_hat = pred_image.get_fdata()\n",
    "\n",
    "\n",
    "# Extract middle slice along the z-axis\n",
    "selected_z = 32\n",
    "x_slice = x[:, :, selected_z]\n",
    "y_slice = y[:, :, selected_z]\n",
    "y_hat_slice = y_hat[:, :, selected_z]\n",
    "\n",
    "# Define a colormap where each class ID maps to an RGB color\n",
    "color_map = {\n",
    "    0: [0, 0, 0],  # Black for class 0 (background)\n",
    "    1: [0, 255, 0],  # Green for class 1 (CSF / femoral cartilage)\n",
    "    2: [255, 0, 0],  # Red for class 2 (cortical GM / tibial cartilage)\n",
    "    3: [0, 0, 255],  # Blue for class 3 (WM / patellar cartilage)\n",
    "    4: [255, 255, 0],  # Yellow for class 4 (deep GM / femur)\n",
    "    5: [0, 255, 255],  # Cyan for class 5 (brain stem / tibia)\n",
    "    6: [255, 0, 255],  # Magenta for class 6 (cerebellum / patella)\n",
    "}\n",
    "\n",
    "# Transform x\n",
    "x_slice = cv2.normalize(\n",
    "    x_slice, None, 255, 0, cv2.NORM_MINMAX, cv2.CV_8U\n",
    ")\n",
    "x_slice = cv2.cvtColor(x_slice, cv2.COLOR_GRAY2RGB)\n",
    "x_slice = np.transpose(torch.from_numpy(x_slice), axes=[2, 0, 1])\n",
    "\n",
    "# Transform y\n",
    "output_image = np.zeros(\n",
    "    (y_slice.shape[0], y_slice.shape[1], 3), dtype=np.uint8\n",
    ")\n",
    "for value, color in color_map.items():\n",
    "    mask = y_slice == value\n",
    "    output_image[mask] = color\n",
    "y_slice = np.transpose(torch.from_numpy(output_image), axes=[2, 0, 1])\n",
    "y_slice = torch.from_numpy(\n",
    "    cv2.addWeighted(x_slice.numpy(), 0.5, y_slice.numpy(), 0.5, 0)\n",
    ").permute(1,2,0)\n",
    "\n",
    "# Transform y_hat\n",
    "output_image = np.zeros(\n",
    "    (y_hat_slice.shape[0], y_hat_slice.shape[1], 3), dtype=np.uint8\n",
    ")\n",
    "for value, color in color_map.items():\n",
    "    mask = y_hat_slice == value\n",
    "    output_image[mask] = color\n",
    "y_hat_slice = np.transpose(\n",
    "    torch.from_numpy(output_image), axes=[2, 0, 1]\n",
    ")\n",
    "y_hat_slice = torch.from_numpy(\n",
    "    cv2.addWeighted(x_slice.numpy(), 0.5, y_hat_slice.numpy(), 0.5, 0)\n",
    ").permute(1,2,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(y_hat_slice)\n",
    "plt.axis('off')\n",
    "plt.savefig(f'{identifier}_y_hat_{selected_z}.png', bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(y_slice)\n",
    "plt.axis('off')\n",
    "plt.savefig(f'{identifier}_y_{selected_z}.png', bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kseg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
