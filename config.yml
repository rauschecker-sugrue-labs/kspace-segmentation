###############################################################################
#                               kseg config                                   #
###############################################################################
version: 1.0.0

# Define the general training parameters here
datasets:
  UCSF51Lesion: /path/to/dataset/
  CNSLymphomaSS: /path/to/dataset/
  CNSLymphomaTissue: /path/to/dataset/
  Knee: /path/to/dataset/
  UPennGBMSS: /path/to/dataset/
  UPennGBMTumor: /path/to/dataset/
  OasisTissue: /path/to/dataset/

# Define the general training parameters here
training:
  epochs: 100
  lr: 0.01
  criterion: MSELoss
  optimizer_class: Lamb
  step_size: 300
  scheduler_class: StepLR

# Define the model-specific parameters here
models:
  MLP:
    hidden_factor: 1
    depth: 3

  PerceiverIO:
    num_frequency_bands: 0
    num_latents: 512
    num_latent_channels: 1024
    num_cross_attention_heads: 4
    num_cross_attention_layers: 8
    num_self_attention_heads: 4
    num_self_attention_layers_per_block: 6
    num_self_attention_blocks: 8
    dropout: 0.1

  SkipMLP:
    hidden_factor: 1
    depth_per_block: 1
    depth: 1

  ResMLP:
    hidden_factor: 1
    depth: 6
    layerscale_init: 0.2

  Transformer:
    hidden_factor: 1
    depth: 2
    num_frequency_bands: 0

# Define the hyperparameter space for each model here
tuning:
  MLP:
    hidden_factor: [1, 2]
    depth: [1, 3]
    step_size: [300, 600]
    lr: [0.01, 0.005]
    optimizer_class: [Adam, Lamb]

  PerceiverIO:
    num_frequency_bands: [0, 32]
    num_latents: [512, 1024]
    num_latent_channels: [1024, 2048]
    num_cross_attention_layers: [4, 8]
    num_self_attention_layers_per_block: [3, 6]
    num_self_attention_blocks: [4, 8]
    dropout: [0.0, 0.1, 0.2]

  SkipMLP:
    hidden_factor: [1, 2]
    depth: [1, 2]

  ResMLP:
    depth: [3, 6]
    lr: [0.01, 0.005]
